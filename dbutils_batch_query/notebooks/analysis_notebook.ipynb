{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Example Data Analysis with dbutils_batch_query\n",
        "\n",
        "This notebook demonstrates how to use the `dbutils_batch_query` package for data analysis tasks. We'll walk through a complete workflow including:\n",
        "\n",
        "1. Data import and preprocessing\n",
        "2. Exploratory data analysis\n",
        "3. Statistical analysis\n",
        "4. Time series analysis and forecasting\n",
        "\n",
        "This example notebook can serve as a starting point for your own analysis projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 1. Setup and Data Import\n",
        "\n",
        "First, we'll import the necessary packages and prepare our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Import standard data science libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure visualization settings\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "# Import functions from our package\n",
        "from dbutils_batch_query.data_import import load_csv, clean_data, transform_data\n",
        "from dbutils_batch_query.example_analysis import descriptive_stats, correlation_analysis, time_series_analysis\n",
        "\n",
        "# Display package version\n",
        "import dbutils_batch_query\n",
        "print(f\"{{ project_name }} version: {{{ project_name }}.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### Generate Sample Data\n",
        "\n",
        "Let's create some synthetic data for our examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create sample tabular data\n",
        "n_samples = 500\n",
        "data = {\n",
        "    'numeric_feature_1': np.random.normal(loc=50, scale=10, size=n_samples),\n",
        "    'numeric_feature_2': np.random.normal(loc=25, scale=5, size=n_samples),\n",
        "    'category': np.random.choice(['A', 'B', 'C'], size=n_samples, p=[0.5, 0.3, 0.2])\n",
        "}\n",
        "\n",
        "# Add some correlation between features\n",
        "data['numeric_feature_3'] = data['numeric_feature_1'] * 0.6 + data['numeric_feature_2'] * 0.4 + np.random.normal(0, 5, n_samples)\n",
        "\n",
        "# Add some missing values\n",
        "missing_indices = np.random.choice(n_samples, size=int(n_samples * 0.05), replace=False)\n",
        "data['numeric_feature_1'][missing_indices] = np.nan\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the first few rows\n",
        "print(f\"Sample data shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### Data Cleaning and Preprocessing\n",
        "\n",
        "Now we'll clean the data using functions from our `data_import` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Check missing values before cleaning\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Clean the data\n",
        "cleaned_df = clean_data(\n",
        "    df,\n",
        "    drop_duplicates=True,\n",
        "    fill_na={'numeric_feature_1': df['numeric_feature_1'].mean()}\n",
        ")\n",
        "\n",
        "# Check missing values after cleaning\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(cleaned_df.isnull().sum())\n",
        "\n",
        "# Transform the data\n",
        "transformed_df = transform_data(\n",
        "    cleaned_df,\n",
        "    normalize_cols=['numeric_feature_1', 'numeric_feature_2', 'numeric_feature_3'],\n",
        "    categorical_cols=['category']\n",
        ")\n",
        "\n",
        "print(\"\\nTransformed data:\")\n",
        "transformed_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 2. Exploratory Data Analysis\n",
        "\n",
        "Let's perform some basic exploratory data analysis using our `example_analysis` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Calculate descriptive statistics\n",
        "stats_df, plots = descriptive_stats(\n",
        "    cleaned_df,\n",
        "    numeric_cols=['numeric_feature_1', 'numeric_feature_2', 'numeric_feature_3'],\n",
        "    include_plots=True\n",
        ")\n",
        "\n",
        "# Display the statistics\n",
        "print(\"Descriptive Statistics:\")\n",
        "stats_df.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Show distribution plots for feature 1\n",
        "plots['numeric_feature_1']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Perform correlation analysis\n",
        "corr_df, corr_plot = correlation_analysis(\n",
        "    cleaned_df,\n",
        "    numeric_cols=['numeric_feature_1', 'numeric_feature_2', 'numeric_feature_3'],\n",
        "    method='pearson',\n",
        "    threshold=0.0,\n",
        "    include_plot=True\n",
        ")\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "print(corr_df.round(3))\n",
        "\n",
        "# Display the correlation plot\n",
        "corr_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### Group Analysis by Category\n",
        "\n",
        "Let's analyze our data grouped by the categorical variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Group statistics by category\n",
        "group_stats = cleaned_df.groupby('category')[['numeric_feature_1', 'numeric_feature_2', 'numeric_feature_3']].agg(['mean', 'std'])\n",
        "print(\"Group Statistics by Category:\")\n",
        "group_stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Visualize distributions by category\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, feature in enumerate(['numeric_feature_1', 'numeric_feature_2', 'numeric_feature_3']):\n",
        "    sns.boxplot(x='category', y=feature, data=cleaned_df, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {feature} by Category')\n",
        "    axes[i].grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 3. Statistical Testing\n",
        "\n",
        "Let's perform statistical tests to compare groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "from dbutils_batch_query.example_analysis import run_t_test\n",
        "\n",
        "# Extract data for groups A and B for feature 1\n",
        "group_a = cleaned_df[cleaned_df['category'] == 'A']['numeric_feature_1']\n",
        "group_b = cleaned_df[cleaned_df['category'] == 'B']['numeric_feature_1']\n",
        "\n",
        "# Run t-test between groups A and B\n",
        "t_test_results, t_test_plot = run_t_test(\n",
        "    group_a,\n",
        "    group_b,\n",
        "    equal_var=True,\n",
        "    alternative='two-sided',\n",
        "    include_plot=True\n",
        ")\n",
        "\n",
        "print(\"T-test Results for Feature 1 (Group A vs. Group B):\")\n",
        "for key, value in t_test_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Show the t-test plot\n",
        "t_test_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 4. Time Series Analysis and Forecasting\n",
        "\n",
        "Now let's create and analyze some time series data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Create a time series with trend, seasonality, and noise\n",
        "periods = 48  # 4 years of monthly data\n",
        "dates = pd.date_range(start='2021-01-01', periods=periods, freq='M')\n",
        "\n",
        "# Components\n",
        "time_idx = np.arange(periods)\n",
        "trend = 0.2 * time_idx  # Linear trend\n",
        "seasonality = 5 * np.sin(2 * np.pi * time_idx / 12)  # Yearly seasonality\n",
        "noise = np.random.normal(0, 1, periods)  # Random noise\n",
        "\n",
        "# Combine components\n",
        "ts_values = trend + seasonality + noise\n",
        "time_series = pd.Series(ts_values, index=dates)\n",
        "\n",
        "# Plot the time series\n",
        "plt.figure(figsize=(14, 6))\n",
        "time_series.plot()\n",
        "plt.title('Sample Time Series Data (Monthly, 4 Years)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Perform time series analysis\n",
        "ts_results, ts_plots = time_series_analysis(\n",
        "    time_series,\n",
        "    periods=12,  # Forecast next 12 months\n",
        "    seasonal=True,\n",
        "    seasonal_periods=12,  # Monthly data\n",
        "    include_plots=True\n",
        ")\n",
        "\n",
        "# Display the decomposition and forecast plots\n",
        "ts_plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### Forecast Analysis\n",
        "\n",
        "Let's examine the forecast values in more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Display the forecast\n",
        "print(\"Forecast for the next 12 months:\")\n",
        "forecast = ts_results['forecast']\n",
        "forecast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": [
        "# Create a more detailed forecast plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot historical data\n",
        "time_series.plot(label='Historical Data', color='blue')\n",
        "\n",
        "# Plot forecast\n",
        "forecast.plot(label='Forecast', color='red', linestyle='--')\n",
        "\n",
        "# Add trend line from decomposition if available\n",
        "if 'decomposition' in ts_results:\n",
        "    trend = ts_results['decomposition'].trend\n",
        "    trend.plot(label='Trend', color='green', alpha=0.7)\n",
        "\n",
        "    # Extend trend line for forecast period (simple linear projection)\n",
        "    last_trend_value = trend.dropna().iloc[-1]\n",
        "    trend_diff = (trend.dropna().iloc[-1] - trend.dropna().iloc[-13]) / 12  # Annual trend change\n",
        "    forecast_trend = pd.Series(\n",
        "        [last_trend_value + trend_diff * (i+1) for i in range(len(forecast))],\n",
        "        index=forecast.index\n",
        "    )\n",
        "    forecast_trend.plot(color='green', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.title('Time Series Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated the use of the `dbutils_batch_query` package for data analysis tasks:\n",
        "\n",
        "1. **Data Import and Processing**:\n",
        "   - Created and cleaned sample data\n",
        "   - Transformed features with normalization and encoding\n",
        "\n",
        "2. **Exploratory Data Analysis**:\n",
        "   - Calculated descriptive statistics\n",
        "   - Analyzed correlations between variables\n",
        "   - Compared groups with statistical tests\n",
        "\n",
        "3. **Time Series Analysis**:\n",
        "   - Created a synthetic time series with trend and seasonality\n",
        "   - Decomposed the series into trend, seasonal, and residual components\n",
        "   - Generated forecasts for future periods\n",
        "\n",
        "This workflow can serve as a starting point for your own analysis projects using the `dbutils_batch_query` package."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}